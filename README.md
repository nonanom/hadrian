Here’s how you can explain the purpose and functionality of each workflow and how to use them:

---

# Hadrian Infrastructure Coding Exam
## GitHub Repository Overview

This repository is designed to manage and automate various AWS infrastructure tasks using GitHub Actions workflows. Below is an overview of the key capabilities of this repository, along with instructions on how to use each workflow.

### Key Capabilities

1. **Create All the AWS Infrastructure**:
   - **Workflow File**: `create-all-the-aws-infrastructure.yml`
   - **Description**: This workflow sets up the entire AWS infrastructure required for the project. It provisions resources such as EC2 instances, RDS databases, and S3 buckets as defined in the Terraform configuration. Additionally, it automatically creates the Terraform state file's remote backend, ensuring that your infrastructure state is securely managed.
   - **How to Use**: 
     1. Trigger this workflow manually via GitHub Actions (`workflow_dispatch`).
     2. It will create all necessary AWS resources.
     3. After running this workflow, make sure to set up the `RDS_ENDPOINT` and `EC2_PUBLIC_DNS` variables in your GitHub repository with the output values generated by Terraform.

2. **Upload Data CSV to the S3 Bucket**:
   - **Workflow File**: `upload-data-csv-to-the-s3-bucket.yml`
   - **Description**: This workflow uploads a `data.csv` file to the S3 bucket. It prepares the data for processing by the ETL job.
   - **How to Use**:
     1. Place your `data.csv` file in the `data/` directory of the repository.
     2. Trigger this workflow manually via GitHub Actions.
     3. The workflow will upload the CSV file to the specified S3 bucket.

3. **Run ETL Job on the EC2 Instance**:
   - **Workflow File**: `run-etl-job-on-the-ec2-instance.yml`
   - **Description**: This workflow runs an ETL (Extract, Transform, Load) job on the EC2 instance. It executes the necessary scripts to process and transform data. The EC2 instance has access to the RDS, so you can use Boto3 in Python to push the transformed data to the RDS instance at the end if desired, as demonstrated in this setup.
   - **How to Use**:
     1. Modify the `etl-job.py` script in the `scripts/` directory to perform your desired data transformation.
     2. Trigger this workflow manually via GitHub Actions.
     3. The workflow will SSH into the EC2 instance, copy over the modified script, and execute it.
     4. The data can be pushed to RDS using Boto3 in the script.

4. **Teardown Everything on AWS**:
   - **Workflow File**: `teardown-everything-on-aws.yml`
   - **Description**: This workflow removes all AWS resources that were provisioned during the infrastructure setup. It effectively cleans up everything by removing what’s listed in the Terraform state file, ensuring no leftover resources in your AWS account.
   - **How to Use**:
     1. Trigger this workflow manually via GitHub Actions when you want to remove all AWS resources created by the infrastructure setup.
     2. The workflow will use Terraform to destroy all resources, cleaning up your AWS environment.

### Additional Information

The repository includes the following directories:

- **Data**: Contains the data files used by the ETL job and other processes.
- **Scripts**: Includes the scripts that are executed by the workflows to perform various tasks, such as running the ETL job or managing infrastructure.

## GitHub Repository Setup for GitHub Actions

This document provides instructions for setting up the necessary secrets and variables in the GitHub repository to ensure the project works correctly after forking the repository.

### AWS Setup

Add the following secrets and variables to your GitHub repository for AWS configuration:

| **Name**               | **Type**  | **Required** | **Description**                                                                 |
|------------------------|-----------|--------------|---------------------------------------------------------------------------------|
| `AWS_ACCESS_KEY_ID`     | Secret    | Yes          | Provide your AWS Access Key ID with appropriate permissions for managing resources in your AWS account.  |
| `AWS_SECRET_ACCESS_KEY` | Secret    | Yes          | Provide your AWS Secret Access Key associated with the above Access Key ID.            |
| `AWS_DEFAULT_REGION`    | Variable  | Yes          | Set this variable to the AWS region where you want your resources to be created (e.g., `us-east-1`).|

### RDS Setup

Add the following secrets and variables to your GitHub repository for RDS configuration:

| **Name**          | **Type**  | **Required** | **Description**                        |
|-------------------|-----------|--------------|----------------------------------------|
| `DB_USERNAME`     | Variable  | Yes          | Set this variable to your database username. Ensure it meets AWS RDS requirements.|
| `DB_PASSWORD`     | Secret    | Yes          | Provide your database password. Make sure it conforms to AWS RDS password requirements.     |

### EC2 Setup

Add the following secrets and variables to your GitHub repository for EC2 configuration:

| **Name**          | **Type**  | **Required** | **Description**                        |
|-------------------|-----------|--------------|----------------------------------------|
| `EC2_PUBLIC_KEY`  | Variable  | Yes          | Generate an SSH key pair using `ssh-keygen -t rsa -b 4096`. Set this variable to the public SSH key, which will be used for SSH access to the EC2 instance. |
| `EC2_PRIVATE_KEY` | Secret    | Yes          | Set this secret to the private SSH key generated above. This key will be used by GitHub Actions to SSH into the EC2 instance as the Ubuntu user. Do not add a passphrase to the key. |

### Tagging Setup

Add the following variable to your GitHub repository for project tagging:

| **Name**          | **Type**  | **Required** | **Description**                        |
|-------------------|-----------|--------------|----------------------------------------|
| `PROJECT_NAME`    | Variable  | Yes          | Set this variable to your project name. It will be used in tagging and naming resources throughout the project.  |

### Post-Setup Configuration

After you create the infrastructure using the `create-all-the-aws-infrastructure.yml` workflow file, you need to add the following variables to your GitHub repository:

| **Name**          | **Type**  | **Required** | **Description**                        |
|-------------------|-----------|--------------|----------------------------------------|
| `RDS_ENDPOINT`    | Variable  | Yes          | Enter the endpoint for the RDS instance. This value will be generated by the Terraform output when you run the infrastructure setup workflow.     |
| `EC2_PUBLIC_DNS`  | Variable  | Yes          | Enter the public DNS for the EC2 instance. This value will also be generated by the Terraform output after running the infrastructure setup workflow.   |

## Author
[Mike Vincent](mailto:michael.thomas.vincent@gmail.com)
```

This document now provides a clear overview of each workflow, along with detailed instructions on how to use them and what steps to take before and after running each workflow. The explanation is designed to guide users through the process of setting up and managing the infrastructure using GitHub Actions.