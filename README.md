# Hadrian Infrastructure Coding Exam

## GitHub Repository Overview

This repository is designed to fulfill the requirements of a take-home infrastructure coding exam. It provides a scalable and secure data platform on AWS, supporting machine learning operations (MLOps). The platform includes an S3 bucket for data storage, an EC2 instance for running ETL jobs, an RDS instance for storing processed data, and a CI/CD pipeline using GitHub Actions to automate deployments. Additionally, the infrastructure is monitored and logged using Amazon CloudWatch.

### Key Capabilities

1. **Create All the AWS Infrastructure**:
   - **Workflow File**: `create-all-the-aws-infrastructure.yml`
   - **Description**: This workflow sets up the entire AWS infrastructure required for the project. It provisions resources such as EC2 instances, RDS databases, and S3 buckets as defined in the Terraform configuration. Additionally, it automatically creates the Terraform state file's remote backend, ensuring that your infrastructure state is securely managed.
   - **How to Use**: 
     1. Trigger this workflow manually via GitHub Actions (`workflow_dispatch`).
     2. It will create all necessary AWS resources, including:
        - An S3 bucket named `<your-name>-hadrian-ml-data-bucket` with versioning enabled.
        - An EC2 instance with the latest Ubuntu AMI, SSH, and HTTP access configured, and Docker installed via user data.
        - An RDS instance running PostgreSQL with security configured to allow access from the EC2 instance.
     3. After running this workflow, make sure to set up the `RDS_ENDPOINT` and `EC2_PUBLIC_DNS` variables in your GitHub repository with the output values generated by Terraform.

2. **Upload Data CSV to the S3 Bucket**:
   - **Workflow File**: `upload-data-csv-to-the-s3-bucket.yml`
   - **Description**: This workflow uploads a `data.csv` file to the S3 bucket. It prepares the data for processing by the ETL job.
   - **How to Use**:
     1. Place your `data.csv` file in the `data/` directory of the repository.
     2. Trigger this workflow manually via GitHub Actions.
     3. The workflow will upload the CSV file to the specified S3 bucket.

3. **Run ETL Job on the EC2 Instance**:
   - **Workflow File**: `run-etl-job-on-the-ec2-instance.yml`
   - **Description**: This workflow runs an ETL (Extract, Transform, Load) job on the EC2 instance. It downloads data from the S3 bucket, processes it (e.g., performs a simple transformation such as changing a word or using regex), and uploads the processed data to the RDS instance. The EC2 instance has access to the RDS, so you can use Boto3 in Python to push the transformed data to the RDS instance at the end if desired.
   - **How to Use**:
     1. Modify the `etl-job.py` script in the `scripts/` directory to perform your desired data transformation.
     2. Trigger this workflow manually via GitHub Actions.
     3. The workflow will SSH into the EC2 instance, copy over the modified script, and execute it.
     4. The data can be pushed to RDS using Boto3 in the script.

4. **Teardown Everything on AWS**:
   - **Workflow File**: `teardown-everything-on-aws.yml`
   - **Description**: This workflow removes all AWS resources that were provisioned during the infrastructure setup. It effectively cleans up everything by removing what’s listed in the Terraform state file, ensuring no leftover resources in your AWS account.
   - **How to Use**:
     1. Trigger this workflow manually via GitHub Actions when you want to remove all AWS resources created by the infrastructure setup.
     2. The workflow will use Terraform to destroy all resources, cleaning up your AWS environment.

## Infrastructure Overview

This Terraform setup creates a fully functional AWS environment for the project. The infrastructure includes an EC2 instance, RDS (PostgreSQL) database, S3 bucket, and associated security configurations, aligned with the homework assignment's requirements.

### EC2 Instance Setup

- **EC2 Instance**: 
  - **AMI**: The latest Ubuntu 20.04 AMI is fetched using a data block.
  - **Instance Type**: `t3.micro`
  - **Security Groups**: The EC2 instance is secured by a security group (`ec2_sg`) that allows SSH (port 22) and HTTP (port 80) traffic from any IP address.
  - **User Data Script**: Upon startup, the instance runs a user data script that:
    - Installs Docker and Docker Compose.
    - Sets up SSH key-based authentication.
    - Installs and configures the Amazon CloudWatch Agent to collect metrics and logs.
  - **CloudWatch**: Logs and metrics from the EC2 instance are sent to CloudWatch, with a log group and stream specifically configured for this instance.
  - **IAM Role**: The EC2 instance is associated with an IAM role that allows it to interact with CloudWatch.

### RDS (PostgreSQL) Setup

- **RDS Instance**:
  - **Engine**: PostgreSQL version 13.
  - **Instance Type**: `db.t3.micro`.
  - **Security Group**: The RDS instance is secured by a security group (`rds_sg`) that allows traffic on port 5432 from the EC2 instance’s security group.
  - **Backup and Maintenance**: The RDS instance is configured with a daily backup retention period and a maintenance window.
  - **Public Accessibility**: The RDS instance is not publicly accessible, ensuring that it can only be accessed from within the security perimeter.

### S3 Bucket Setup

- **S3 Bucket**:
  - **Bucket Name**: Named based on the project name, the S3 bucket is used to store data files, such as the `data.csv` file uploaded via the GitHub Actions workflow.
  - **Versioning**: Enabled on the bucket to keep track of different versions of objects stored within.

## GitHub Repository Setup for GitHub Actions

This document provides instructions for setting up the necessary secrets and variables in the GitHub repository to ensure the project works correctly after forking the repository.

### AWS Setup

Add the following secrets and variables to your GitHub repository for AWS configuration:

| **Name**               | **Type**  | **Required** | **Description**                                                                 |
|------------------------|-----------|--------------|---------------------------------------------------------------------------------|
| `AWS_ACCESS_KEY_ID`     | Secret    | Yes          | Provide your AWS Access Key ID with appropriate permissions for managing resources in your AWS account.  |
| `AWS_SECRET_ACCESS_KEY` | Secret    | Yes          | Provide your AWS Secret Access Key associated with the above Access Key ID.            |
| `AWS_DEFAULT_REGION`    | Variable  | Yes          | Set this variable to the AWS region where you want your resources to be created (e.g., `us-east-1`).|

### RDS Setup

Add the following secrets and variables to your GitHub repository for RDS configuration:

| **Name**          | **Type**  | **Required** | **Description**                        |
|-------------------|-----------|--------------|----------------------------------------|
| `DB_USERNAME`     | Variable  | Yes          | Set this variable to your database username. Ensure it meets AWS RDS requirements.|
| `DB_PASSWORD`     | Secret    | Yes          | Provide your database password. Make sure it conforms to AWS RDS password requirements.     |

### EC2 Setup

Add the following secrets and variables to your GitHub repository for EC2 configuration:

| **Name**          | **Type**  | **Required** | **Description**                        |
|-------------------|-----------|--------------|----------------------------------------|
| `EC2_PUBLIC_KEY`  | Variable  | Yes          | Generate an SSH key pair using `ssh-keygen -t rsa -b 4096`. Set this variable to the public SSH key, which will be used for SSH access to the EC2 instance. |
| `EC2_PRIVATE_KEY` | Secret    | Yes          | Set this secret to the private SSH key generated above. This key will be used by GitHub Actions to SSH into the EC2 instance as the Ubuntu user. Do not add a passphrase to the key. |

### Tagging Setup

Add the following variable to your GitHub repository for project tagging:

| **Name**          | **Type**  | **Required** | **Description**                        |
|-------------------|-----------|--------------|----------------------------------------|
| `PROJECT_NAME`    | Variable  | Yes          | Set this variable to your project name. It will be used in tagging and naming resources throughout the project.  |

### Post-Setup Configuration

After you create the infrastructure using the `create-all-the-aws-infrastructure.yml` workflow file, you need to add the following variables to your GitHub repository:

| **Name**          | **Type**  | **Required** | **Description**                        |
|-------------------|-----------|--------------|----------------------------------------|
| `RDS_ENDPOINT`    | Variable  | Yes          | Enter the endpoint for the RDS instance. This value will be generated by the Terraform output when you run the infrastructure setup workflow.     |
| `EC2_PUBLIC_DNS`  | Variable  | Yes          | Enter the public DNS for the EC2 instance. This value will also be generated by the Terraform output after running the infrastructure setup

 workflow.   |

## Author
[Mike Vincent](mailto:michael.thomas.vincent@gmail.com)
